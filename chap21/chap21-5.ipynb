{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install basic toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate transformers safetensors opencv-python diffusers -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SDXL model and ControlNet's canny model\n",
    "from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline, AutoencoderKL\n",
    "from diffusers.utils import load_image\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# ControlNet's intensity parameter\n",
    "controlnet_conditioning_scale = 0.5  # recommended for good generalization\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"diffusers/controlnet-canny-sdxl-1.0-mid\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
    "pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    controlnet=controlnet,\n",
    "    vae=vae,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Hugging Face's logo image\n",
    "image = load_image(\"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/hf-logo.png\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract edges for the original image\n",
    "image = np.array(image)\n",
    "image = cv2.Canny(image, 100, 200)\n",
    "image = image[:, :, None]\n",
    "image = np.concatenate([image, image, image], axis=2)\n",
    "image = Image.fromarray(image)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine with ControlNet for line drawing\n",
    "prompt = \"aerial view, a futuristic research complex in a bright foggy jungle, hard lighting\"\n",
    "negative_prompt = \"low quality, bad quality, sketches\"\n",
    "\n",
    "controlnet_conditioning_scale = 0.5  # recommended for good generalization\n",
    "\n",
    "images = pipe(\n",
    "    prompt, negative_prompt=negative_prompt, image=image, controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
    ").images\n",
    "\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# This function is used to show multiple images\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows * cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    grid_w, grid_h = grid.size\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try other line drawing effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "from diffusers.utils import load_image\n",
    "import torch\n",
    "\n",
    "image_original = load_image(\"https://media.discordapp.net/attachments/1092064974794391644/1194478479710887976/00001-1382219160.jpeg?ex=65b07fc5&is=659e0ac5&hm=210378d034d75043a598b7ec6445dd7052cfc31b46af918c2269ffc97710f310&=&format=webp&width=960&height=960\")\n",
    "image_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract canny edges\n",
    "image = np.array(image_original)\n",
    "image = cv2.Canny(image, 100, 200)\n",
    "image = image[:, :, None]\n",
    "image = np.concatenate([image, image, image], axis=2)\n",
    "image = Image.fromarray(image)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine with ControlNet for line drawing\n",
    "prompt = \"A cartoon-style wizard wearing a blue wizard hat, with a grey-white beard, blue eyes, a black cloak, and a background including green trees and plants, and a round disc decoration with exquisite texture.\"\n",
    "generator = torch.manual_seed(1025)\n",
    "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\"\n",
    "\n",
    "controlnet_conditioning_scale = 0.6  # recommended for good generalization\n",
    "\n",
    "images = pipe(\n",
    "    [prompt]*4, num_inference_steps=50, negative_prompt=[negative_prompt]*4, image=image, controlnet_conditioning_scale=controlnet_conditioning_scale,generator = generator\n",
    ").images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid(images, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landscape line drawing\n",
    "image_original = load_image(\"https://media.discordapp.net/attachments/1092064974794391644/1194486606644649995/00031-1741371519.jpeg?ex=65b08757&is=659e1257&hm=548456541fa6cacfd84cd0744ee9ab4d679ed37058a3316ab43d68fed7bc4572&=&format=webp&width=960&height=960\")\n",
    "image_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(image_original)\n",
    "image = cv2.Canny(image, 100, 200)\n",
    "image = image[:, :, None]\n",
    "image = np.concatenate([image, image, image], axis=2)\n",
    "image = Image.fromarray(image)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A white unicorn with a purple horn, colorful fur, black eyes, and a background of vibrant plants and flowers.\"\n",
    "generator = torch.manual_seed(1025)\n",
    "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\"\n",
    "\n",
    "controlnet_conditioning_scale = 0.5  # recommended for good generalization\n",
    "\n",
    "images = pipe(\n",
    "    [prompt]*4, num_inference_steps=50, negative_prompt=[negative_prompt]*4, image=image, controlnet_conditioning_scale=controlnet_conditioning_scale,generator = generator\n",
    ").images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid(images, 2, 2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
