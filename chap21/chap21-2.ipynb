{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing basic toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq diffusers==0.14.0 transformers xformers git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq opencv-contrib-python\n",
    "!pip install -qq controlnet_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "from diffusers.utils import load_image\n",
    "import torch\n",
    "\n",
    "image = load_image(\n",
    "    \"https://media.discordapp.net/attachments/1092064974794391644/1194499469895553094/file-BeqG1EHHYHBrPF9W5Nj4uv2n.png?ex=65b09352&is=659e1e52&hm=ed922e13961494259d388ceb64f7cf4b4114ba5b788dc3df3fe743088fe742bb&=&format=webp&quality=lossless&width=1005&height=1005\"\n",
    ")\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "\n",
    "# Extract depth information\n",
    "depth_estimator = pipeline('depth-estimation')\n",
    "image = depth_estimator(image)['depth']\n",
    "image = np.array(image)\n",
    "image = image[:, :, None]\n",
    "image = np.concatenate([image, image, image], axis=2)\n",
    "control_image = Image.fromarray(image)\n",
    "control_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ControlNet1.1's depth model\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/control_v11f1p_sd15_depth\")\n",
    "pipeline = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "\t\"runwayml/stable-diffusion-v1-5\", controlnet=controlnet\n",
    ")\n",
    "pipeline.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"A bulldog wearing sunglasses and a big gold chain around its neck, standing against a wall, cartoon style, best quality\"] * 2\n",
    "generator = torch.manual_seed(0)\n",
    "image = pipeline(prompt, num_inference_steps=30, generator=generator, image=control_image, height = 512, width = 512).images\n",
    "\n",
    "# image.save('image_out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For displaying images\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows * cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    grid_w, grid_h = grid.size\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "image_grid(image, 1, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_painting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
